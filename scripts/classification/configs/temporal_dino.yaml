# Temporal model with DinoV2 encoder
# Processes sequences of frames for detecting temporal patterns

experiment:
  name: "temporal_dinov2_small"
  project: "TendonClassifier"
  seed: 42

model:
  type: "temporal"
  encoder:
    name: "dinov2_small"
    pretrained: true
    freeze: true  # Critical: must freeze for small dataset
  temporal:
    num_frames: 5
    aggregation: "attention"  # attention | mean | lstm
  fusion:
    type: "attention"
    hidden_dim: 128
  num_classes: 4
  use_force: true
  use_depth_head: true

data:
  manifest: "../labeling/output/gt_dataset/gt_manifest.csv"
  img_size: 224
  normalization:
    type: "imagenet"
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  subtraction:
    enabled: false
  augmentation:
    enabled: false

training:
  epochs: 100
  batch_size: 16  # Smaller batch size for temporal model (more memory)
  lr: 0.0001
  weight_decay: 0.0001
  optimizer: "adamw"
  scheduler:
    type: "cosine"
    warmup_epochs: 5
  loss:
    class_weights: "balanced"
    depth_weight: 0.1
  val_ratio: 0.2
  split_by: "run"

checkpoint:
  dir: "checkpoints"
  save_best: true
  save_last: true
  save_every_n_epochs: 5

logging:
  wandb:
    enabled: true
    tags: ["temporal", "dinov2", "sequence"]
  csv:
    enabled: true
  print_every: 1
